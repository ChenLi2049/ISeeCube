{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d545ad-69c5-407b-bae2-b4cddba8aa95",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17fdce-a571-4a00-af7a-0e90904e926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "from torchinfo import summary\n",
    "from torch import optim\n",
    "\n",
    "from fastai.vision.all import DataLoaders, Learner, CSVLogger\n",
    "from fastai.optimizer import OptimWrapper\n",
    "\n",
    "from torchscale.architecture.config import EncoderConfig\n",
    "from torchscale.architecture.encoder import Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a04103-aae1-4468-8400-d5f9e1239056",
   "metadata": {},
   "source": [
    "## §0 `utils.py` def `seed_everything`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f993def-3c3f-4869-8204-dd00b0dfe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f20556-2ddc-4a3c-9253-951627fb7473",
   "metadata": {},
   "source": [
    "## §1 `dataset.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a2141-4c6a-44aa-8419-240c7da8b6b4",
   "metadata": {},
   "source": [
    "### §1.1 def `prepare_sensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecfe2a-01d9-442a-bf62-540c081f306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sensors():\n",
    "    sensors = pd.read_csv(\"data/sensor_geometry.csv\").astype(\n",
    "        {\n",
    "            \"sensor_id\": np.int16,\n",
    "            \"x\": np.float32,\n",
    "            \"y\": np.float32,\n",
    "            \"z\": np.float32,\n",
    "        }\n",
    "    )\n",
    "    sensors[\"string\"] = 0\n",
    "    sensors[\"qe\"] = 0  # or 1, Quantum Efficiency\n",
    "\n",
    "    for i in range(len(sensors) // 60):\n",
    "        start, end = i * 60, (i * 60) + 60\n",
    "        sensors.loc[start:end, \"string\"] = i# classify sensors with string\n",
    "\n",
    "        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n",
    "        if i in range(78, 86):\n",
    "            start_veto, end_veto = i * 60, (i * 60) + 10\n",
    "            start_core, end_core = end_veto + 1, (i * 60) + 60\n",
    "            sensors.loc[start_core:end_core, \"qe\"] = 1  # 1.35\n",
    "\n",
    "    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n",
    "    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n",
    "    sensors[\"x\"] /= 500\n",
    "    sensors[\"y\"] /= 500\n",
    "    sensors[\"z\"] /= 500\n",
    "\n",
    "    return sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2e679-f517-4276-85b0-fea82a83f956",
   "metadata": {},
   "source": [
    "### §1.2 class `IceCubeDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15242bda-4175-4dd4-8b57-3d4e393bc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, dim_base=128, batch_id=1):\n",
    "        # dim_base for nomalize\n",
    "        self.dim_base = dim_base\n",
    "        \n",
    "        # 1. load `batch_1.parquet` and concat the same event_id together\n",
    "        batch_1 = pd.read_parquet(os.path.join(\"data/train\", \"batch_\"+str(batch_id)+\".parquet\"))# data/train/batch_1.parquet\n",
    "        batch_1 = batch_1.groupby('event_id').agg({\n",
    "            'sensor_id': list,\n",
    "            'time': list,\n",
    "            'charge': list,\n",
    "            'auxiliary': list\n",
    "        })\n",
    "        batch_1.reset_index(drop=True, inplace=True)# event_id -> index\n",
    "        self.batch_1 = batch_1\n",
    "        \n",
    "        # 2. geometry\n",
    "        sensors = prepare_sensors()\n",
    "        self.geometry = torch.from_numpy(sensors[[\"x\", \"y\", \"z\"]].values.astype(np.float32))\n",
    "        self.qe = sensors[\"qe\"].values\n",
    "        \n",
    "        # 3. load `train_meta.parquet` to get target: azimuth and zenith\n",
    "        train_meta = pd.read_parquet('data/train_meta.parquet')\n",
    "        batch_1_meta = train_meta[train_meta['batch_id'] == batch_id]\n",
    "        batch_1_meta.reset_index(drop=True, inplace=True)# event_id -> index\n",
    "        self.batch_1_meta = batch_1_meta\n",
    "        \n",
    "        assert len(self.batch_1)==len(self.batch_1_meta), \"batch_1 and batch_1_meta length doesn't match\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 1. for each event in `batch_1.parquet`\n",
    "        batch_1_event = self.batch_1.loc[index]\n",
    "        sensor_id = np.array(batch_1_event[\"sensor_id\"])\n",
    "        time = np.array(batch_1_event[\"time\"])\n",
    "        time = (time - 1e4) / 3e4\n",
    "        charge = np.array(batch_1_event[\"charge\"])\n",
    "        charge = np.log10(charge) / 3.0\n",
    "        auxiliary = np.array(batch_1_event[\"auxiliary\"])\n",
    "\n",
    "        # normalize so that the length of each event is 128\n",
    "        dim_base = len(sensor_id)\n",
    "        # the output of this method\n",
    "        dim_base_0 = dim_base\n",
    "        if dim_base < self.dim_base:\n",
    "            # assignment\n",
    "            sensor_id = np.pad(sensor_id, (0, max(0, self.dim_base - dim_base)))\n",
    "            time = np.pad(time, (0, max(0, self.dim_base - dim_base)))\n",
    "            charge = np.pad(charge, (0, max(0, self.dim_base - dim_base)))\n",
    "            auxiliary = np.pad(auxiliary, (0, max(0, self.dim_base - dim_base)))\n",
    "        else:\n",
    "            # generate a randomly arranged index array ids\n",
    "            ids = torch.randperm(dim_base).numpy()\n",
    "            # negtive index\n",
    "            auxiliary_n = np.where(~auxiliary)[0]\n",
    "            # positive index\n",
    "            auxiliary_p = np.where(auxiliary)[0]\n",
    "            # choose as many as ids in the negtive index\n",
    "            ids_n = ids[auxiliary_n][: min(self.dim_base, len(auxiliary_n))]\n",
    "            # the rest is positive index\n",
    "            ids_p = ids[auxiliary_p][: min(self.dim_base - len(ids_n), len(auxiliary_p))]\n",
    "            # concat into a new index\n",
    "            ids = np.concatenate([ids_n, ids_p])\n",
    "            # sort the index (from small to big)\n",
    "            ids.sort()\n",
    "            # assignment\n",
    "            sensor_id = sensor_id[ids]\n",
    "            time = time[ids]\n",
    "            charge = charge[ids]\n",
    "            auxiliary = auxiliary[ids]\n",
    "            dim_base = len(ids)\n",
    "\n",
    "        # 2. geometry\n",
    "        sensor_id = torch.from_numpy(sensor_id).long()\n",
    "        pos = self.geometry[sensor_id]\n",
    "        pos[dim_base:] = 0\n",
    "        qe = self.qe[sensor_id]\n",
    "        qe[dim_base:] = 0\n",
    "        \n",
    "        # 3. target\n",
    "        azimuth = self.batch_1_meta.loc[index].azimuth\n",
    "        zenith = self.batch_1_meta.loc[index].zenith\n",
    "        target = np.array([azimuth, zenith]).astype(np.float32)\n",
    "        target = torch.from_numpy(target)\n",
    "        \n",
    "        # 4. mask\n",
    "        mask = torch.zeros(self.dim_base, dtype=torch.bool)\n",
    "        mask[:dim_base] = True\n",
    "\n",
    "        return {\n",
    "            \"time\": torch.from_numpy(time).float(),\n",
    "            \"charge\": torch.from_numpy(charge).float(),\n",
    "            \"auxiliary\": torch.from_numpy(auxiliary).long(),\n",
    "            \"pos\": pos,\n",
    "            \"mask\": mask,\n",
    "            \"qe\": qe,\n",
    "            \"dim_base_0\": dim_base_0\n",
    "        }, {\"target\": target}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68124994-f578-4047-a8f6-ab2e9215345e",
   "metadata": {},
   "source": [
    "## §2 `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b8bc8-544b-44da-bfd3-589c9844fbc0",
   "metadata": {},
   "source": [
    "### §2.1 class `SinusoidalPosEmb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb49ece-a629-4e75-a755-797339ca39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):# Sinusoidal Position Embedding\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[..., None] * emb[None, ...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214b931-47d0-4055-8701-17328ce46d72",
   "metadata": {},
   "source": [
    "### §2.2 class `IceCubeEmbedding`\n",
    "\n",
    "- `dim_base` is the dimension of normalize, see `IceCubeDataset`, `dim` is the dimension of embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156ac33-18c6-4137-8cef-a1f9476f04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceCubeEmbedding(nn.Module):\n",
    "    def __init__(self, dim=384, dim_base=128):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "        self.aux_emb = nn.Embedding(2, dim_base // 2)\n",
    "        self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "            nn.LayerNorm(6 * dim_base),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6 * dim_base, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "        charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "        time = x[\"time\"] if Lmax is None else x[\"time\"][:, :Lmax]\n",
    "        auxiliary = x[\"auxiliary\"] if Lmax is None else x[\"auxiliary\"][:, :Lmax]\n",
    "        length = torch.log10(x[\"dim_base_0\"].to(dtype=pos.dtype))\n",
    "\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                #self.cls_token,\n",
    "                self.emb(4096 * pos).flatten(-2),\n",
    "                self.emb(1024 * charge),\n",
    "                self.emb(4096 * time),\n",
    "                self.aux_emb(auxiliary),\n",
    "                self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1)\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed0499-ccf6-4c13-afe3-dca9917885b1",
   "metadata": {},
   "source": [
    "### §2.3 class `IceCubeModel`\n",
    "\n",
    "[microsoft/torchscale (github.com)](https://github.com/microsoft/torchscale/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abd901-168e-4379-a015-8853ac447903",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Use `Encoder` from `torchscale`\n",
    "    \n",
    "    ```python\n",
    "    from torchscale.architecture.config import EncoderConfig\n",
    "    from torchscale.architecture.encoder import Encoder\n",
    "\n",
    "    encoder_config = EncoderConfig(encoder_embed_dim = 384)\n",
    "    encoder = Encoder(encoder_config)\n",
    "\n",
    "    # to test encoder:\n",
    "    # https://github.com/microsoft/torchscale/blob/main/tests/test_encoder.py\n",
    "    dummy = torch.rand(32, 129, 384)\n",
    "    dummy = encoder(src_tokens=None, token_embeddings=dummy)\n",
    "    dummy = dummy['encoder_out']\n",
    "    print(dummy.shape)\n",
    "    ```\n",
    "    \n",
    "    The output is:\n",
    "    \n",
    "    ```python\n",
    "    torch.Size([32, 129, 384])\n",
    "    ```\n",
    "\n",
    "2. First take the slices then use `self.proj_out` to get xyz. 32 is batch_size\n",
    "    \n",
    "    ```python\n",
    "    x = torch.randn(32, 129, 384)\n",
    "    print(x[:, 0, :].shape)\n",
    "    proj_out = nn.Linear(384, 3)\n",
    "    x = proj_out(x[:, 0, :])\n",
    "    print(x.shape)\n",
    "    ```\n",
    "    \n",
    "    The output is:\n",
    "    \n",
    "    ```Shell\n",
    "    torch.Size([32, 384])\n",
    "    torch.Size([32, 3])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993375d-3138-4651-a1f2-4f738da08e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceCubeModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=384,\n",
    "        dim_base=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.icecube_embedding = IceCubeEmbedding(dim, dim_base)\n",
    "        encoder_config_1 = EncoderConfig(\n",
    "            encoder_attention_heads=6,\n",
    "            encoder_embed_dim=dim,\n",
    "            encoder_ffn_embed_dim=1536,# Feed Forward Network\n",
    "            encoder_layers=4,\n",
    "            # relative position bias, see [1910.10683]\n",
    "            rel_pos_buckets=32,\n",
    "            max_rel_pos=dim_base\n",
    "        )\n",
    "        self.encoder_1 = Encoder(encoder_config_1)\n",
    "        self.cls_token = nn.Linear(dim, 1, bias=False)\n",
    "        encoder_config_2 = EncoderConfig(\n",
    "            encoder_attention_heads=12,\n",
    "            encoder_embed_dim=dim,\n",
    "            encoder_ffn_embed_dim=1536,# Feed Forward Network\n",
    "            encoder_layers=12\n",
    "        )\n",
    "        self.encoder_2 = Encoder(encoder_config_2)\n",
    "        self.proj_out = nn.Linear(dim, 3)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        # mask\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        # cls token\n",
    "        batch_size, _ = mask.shape\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        # x\n",
    "        x = self.icecube_embedding(x0, Lmax)\n",
    "        # encoder 1\n",
    "        x = self.encoder_1(src_tokens=None, token_embeddings=x)\n",
    "        x = x['encoder_out']\n",
    "        # concat cls token\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "        # encoder 2\n",
    "        x = self.encoder_2(src_tokens=None, token_embeddings=x)\n",
    "        x = x['encoder_out']\n",
    "        x = self.proj_out(x[:, 0, :])# get cls token, then xyz\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24720a19-9ba2-4168-9e88-7236657996d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(IceCubeModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5b65a-df57-4d48-b3ec-939f11e1a4c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## §3 `loss.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952e38e-40a1-4c8d-a847-b3853061d85d",
   "metadata": {},
   "source": [
    "### §3.1 def `mse_loss`\n",
    "\n",
    "Shape of input:\n",
    "- `pred`: shape is [batch_size, 3], \"3\" is xyz.\n",
    "- `y[\"target\"]`: shape is [batch_size, 2], \"2\" is azimuth and zenith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cbe8a-7269-4831-9dc0-18f4acc03ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse_loss(pred, y):\n",
    "    pred = pred.float()\n",
    "    l = torch.norm(pred.float(), dim=-1).unsqueeze(-1)\n",
    "    pred = pred.float()\n",
    "    \n",
    "    sa2 = torch.sin(y[\"target\"][:, 0])\n",
    "    ca2 = torch.cos(y[\"target\"][:, 0])\n",
    "    sz2 = torch.sin(y[\"target\"][:, 1])\n",
    "    cz2 = torch.cos(y[\"target\"][:, 1])\n",
    "    target = torch.stack([sa2 * sz2, ca2 * sz2, cz2], -1)\n",
    "    \n",
    "    loss = nn.MSELoss()(pred, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1502e44-b94e-463b-87d1-7c1b3aeaf141",
   "metadata": {},
   "source": [
    "### §3.2 def `competition_metric`\n",
    "\n",
    "Shape of input:\n",
    "- `pred`: shape is [batch_size, 3], \"3\" is xyz.\n",
    "- `y[\"target\"]`: shape is [batch_size, 2], \"2\" is azimuth and zenith.\n",
    "\n",
    "Official metric of the kaggle competition：$$\\Psi = \\arccos (\\sin{\\vartheta_\\text{true}}\\sin{\\vartheta_\\text{reco}}(\\cos{{\\varphi_\\text{ture}}}\\cos{{\\varphi_\\text{reco}}}+\\sin{{\\varphi_\\text{ture}}}\\sin{{\\varphi_\\text{reco}}})+\\cos{\\vartheta_\\text{true}}\\cos{\\vartheta_\\text{reco}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c7a19-1e61-45c0-bcda-0e659d491984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(pred, y):\n",
    "    pred = F.normalize(pred.double(), dim=-1)\n",
    "\n",
    "    sa2 = torch.sin(y[\"target\"][:, 0])#sin(azimuth)\n",
    "    ca2 = torch.cos(y[\"target\"][:, 0])\n",
    "    sz2 = torch.sin(y[\"target\"][:, 1])#sin(zenith)\n",
    "    cz2 = torch.cos(y[\"target\"][:, 1])\n",
    "\n",
    "    scalar_prod = (\n",
    "        pred[:, 0] * sa2 * sz2 + pred[:, 1] * ca2 * sz2 + pred[:, 2] * cz2\n",
    "    ).clip(-1 + 1e-8, 1 - 1e-8)\n",
    "    return torch.acos(scalar_prod).abs().mean(-1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39682f2c-c6e0-4a84-bc47-5803967999d2",
   "metadata": {},
   "source": [
    "## §4 `train.py` def `train`\n",
    "\n",
    "https://docs.fast.ai/examples/migrating_pytorch_verbose.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e26562-3aa3-4b68-aa40-9bbca21ee7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    seed_everything(42)\n",
    "    \n",
    "    # load data\n",
    "    dataset = IceCubeDataset(dim_base=128, batch_id=1)\n",
    "    data_size = len(dataset)\n",
    "    train_size = int(0.8 * data_size)# 80% is train_loader\n",
    "    indices = list(range(data_size))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    train_batch_sampler = BatchSampler(\n",
    "        torch.utils.data.SequentialSampler(train_indices),\n",
    "        batch_size=32,\n",
    "        drop_last=False\n",
    "    )\n",
    "    val_batch_sampler = BatchSampler(\n",
    "        torch.utils.data.SequentialSampler(val_indices),\n",
    "        batch_size=32,\n",
    "        drop_last=False\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        num_workers=4,\n",
    "        batch_sampler=train_batch_sampler\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        dataset,\n",
    "        num_workers=1,\n",
    "        batch_sampler=val_batch_sampler\n",
    "    )\n",
    "    dls = DataLoaders(train_loader, val_loader)\n",
    "    model = IceCubeModel().cuda()\n",
    "    \n",
    "    # train\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        path=\"BEiT3_29M_MSE_rel128\",\n",
    "        loss_func=mse_loss,\n",
    "        metrics=competition_metric,\n",
    "        opt_func=partial(OptimWrapper, opt=optim.Adam)\n",
    "    )\n",
    "    learn.fit_one_cycle(16, lr_max=5e-4, cbs=CSVLogger(fname='history.csv', append=True))\n",
    "    learn.save(\"BEiT3_29M_MSE_rel128_0\", with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ffec1-f507-4cbb-8201-a1a71b321e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
